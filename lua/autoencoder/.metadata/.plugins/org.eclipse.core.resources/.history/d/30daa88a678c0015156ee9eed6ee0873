
function loadData(normalizeMean)
  
  train = torch.load('mnist.t7/train_32x32.t7', 'ascii')
  test = torch.load('mnist.t7/test_32x32.t7', 'ascii')
  
  train = train.data
  test = test.data

  traindata = torch.Tensor(train:size()[1],1,32,32)
  for i = 1,train:size()[1] do   
    traindata[i] = train[i]
  end
  traindata:div(traindata:std())
  
  testdata = torch.Tensor(test:size()[1],1,32,32)
  for i = 1,test:size()[1] do   
    testdata[i] = test[i]
  end
  testdata:div(testdata:std())
  
  if normalizeMean then
    traindata:add(-traindata:mean())
    traindata:add(-traindata:mean())
  end
  
  return traindata, testdata
end


function trainModel(steps, batchsize, data, model, criterion, parameters, gradParameters, config, usePhase, noiseLevel)

    for i = 1,steps,batchsize do
    
        local feval = function(x)
            if x ~= parameters then
                parameters:copy(x)
            end

            -- reset gradients
            gradParameters:zero()
            local f = 0 
            for j = 0,batchsize-1 do            
                local activity = data[i+j]
                local phase = torch.Tensor(1,32,32):zero()
                if usePhase then
                    phase = (torch.rand(1,32,32)*2*math.pi)-math.pi
                end
                local input
                local target
                if noiseLevel then
                    corrupted = torch.cmul(activity,randomkit.binomial(torch.Tensor(#activity),1,noiseLevel))
                    input = {torch.cmul(corrupted,torch.cos(phase)),torch.cmul(corrupted,torch.sin(phase))}
                    target = {torch.cmul(activity,torch.cos(phase)),torch.cmul(activity,torch.sin(phase))}
                else
                    input = {torch.cmul(activity,torch.cos(phase)),torch.cmul(activity,torch.sin(phase))}
                    target = input
                end
            
                local output = model:forward(input)
                local err = criterion:forward(output,target) 
                local df_dw = criterion:backward(model.output,target)
                f = f+err
                model:backward(input,df_dw)
            end
            gradParameters:div(batchsize)
            f = f/batchsize
            return f, gradParameters
        end 
    
        optim.sgd(feval, parameters, config)
    
        model:get(1).convBias = torch.Tensor(50):zero()
        model:get(1).convGradBias = torch.Tensor(50):zero()
        model:get(2).convBias = torch.Tensor(50):zero()
        model:get(2).convGradBias = torch.Tensor(50):zero()

    end 
end